# ğŸ“‰ ChurnSense â€” Telecom Customer Churn Prediction

> **Author:** Aditya Mahale  
> **Tech Stack:** Python Â· Pandas Â· NumPy Â· Scikit-learn Â· XGBoost Â· SHAP Â· SQL Â· FastAPI Â· Streamlit Â· Docker

---

## ğŸ¯ What I Built

An end-to-end ML pipeline to predict which telecom customers are likely to churn â€” and more importantly, *why*. I used the [IBM Telco Customer Churn dataset](https://www.kaggle.com/datasets/blastchar/telco-customer-churn) (7,043 customers) and built everything from scratch: data cleaning, feature engineering, model comparison, SHAP explainability, a REST API, and an interactive dashboard.

The goal wasn't just a model â€” it was a system a retention team could actually use.

**Pipeline stages I implemented:**
- **EDA** â€” uncovering churn patterns across tenure, contract type, charges, and services
- **Feature Engineering** â€” derived signals like `charge_per_tenure`, `high_value_at_risk`, `no_support_fiber`, `service_count`
- **Modeling** â€” Logistic Regression, Random Forest, and XGBoost compared via 5-fold stratified CV with tuned decision thresholds
- **Explainability** â€” SHAP values pinpointing *which features* drove each individual prediction
- **Deployment** â€” FastAPI REST endpoint + Streamlit interactive dashboard
- **Monitoring** â€” automated drift detection with alerts when F1 degrades >15%
- **SQL Analysis** â€” 8 cohort and retention queries for marketing team decision-making
- **Docker** â€” fully containerised with `docker-compose`

---

## ğŸ“Š Key Findings

| Segment | Churn Rate |
|---|---|
| Month-to-month contracts | ~43% |
| Fiber optic users | ~42% |
| No tech support | ~41% |
| Two-year contracts | ~12% |
| Customers with tech support | ~15% |

**Overall churn rate:** 26.5%

The strongest churn drivers I found: contract type, tenure, monthly charges, and whether the customer has tech support. These dominated the SHAP feature importance plots consistently.

---

## ğŸ¤– Model Results

| Model | Acc | Prec | Rec | F1 | AUC | CV-AUC |
|---|---|---|---|---|---|---|
| **XGBoost** âœ… | **0.776** | 0.559 | 0.738 | **0.636** | **0.848** | **0.850** |
| Logistic Regression | 0.774 | 0.555 | 0.746 | 0.636 | 0.847 | 0.850 |
| Random Forest | 0.768 | 0.546 | 0.741 | 0.629 | 0.834 | 0.839 |

XGBoost selected as production model â€” tuned via `RandomizedSearchCV` (40 iterations, 5-fold CV) with OOF threshold optimisation. Both predictions and SHAP explanations use XGBoost.

---

## ğŸ—‚ï¸ Project Structure

```
ChurnSense/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ feature_engineering.py   # Feature pipeline (shared across train + serve)
â”‚   â””â”€â”€ cleaned_churn_data.csv   # Generated by model.py (gitignored)
â”œâ”€â”€ models/                      # Saved .pkl files (gitignored)
â”œâ”€â”€ monitoring/                  # Performance logs & drift alerts
â”œâ”€â”€ reports/figures/             # SHAP plots
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py                   # FastAPI prediction API
â”‚   â”œâ”€â”€ monitoring.py            # ModelMonitor class
â”‚   â””â”€â”€ run_monitoring.py        # Scheduled monitoring runner
â”œâ”€â”€ analysis.sql                 # SQL churn segment analysis (8 queries)
â”œâ”€â”€ dashboard.py                 # Streamlit dashboard (EDA + live prediction + SHAP)
â”œâ”€â”€ model.py                     # Full training pipeline â€” run this first
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile.api
â”œâ”€â”€ Dockerfile.dashboard
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Setup

```bash
# 1. Clone
git clone https://github.com/AdityaM24/churnsense.git
cd churnsense

# 2. Virtual environment
python -m venv venv
source venv/bin/activate        # Windows: venv\Scripts\activate

# 3. Install
pip install -r requirements.txt

# 4. Train (downloads dataset, runs feature engineering, saves models + SHAP explainer)
python model.py
```

---

## ğŸš¦ Running It

### Local

```bash
# FastAPI backend
uvicorn src.app:app --reload
# â†’ http://localhost:8000/docs

# Streamlit dashboard (separate terminal)
streamlit run dashboard.py
# â†’ http://localhost:8501
```

### Docker

```bash
docker-compose up --build
# API  â†’ http://localhost:8000
# Dashboard â†’ http://localhost:8501
```

---

## ğŸ” SHAP Explainability

Every prediction in the dashboard comes with a SHAP bar chart showing which features pushed the customer toward or away from churning. This makes the model auditable â€” not a black box.

![SHAP Summary](reports/figures/shap_summary.png)

---

## ğŸ—„ï¸ SQL Analysis

`analysis.sql` has 8 queries I wrote to support business decisions:
- Churn rate by contract type, internet service, tenure stage, payment method
- High-risk segment identification
- Low-balance intervention targeting
- CRM retention list (customers to contact proactively)

---

## ğŸ”„ Monitoring

The `ModelMonitor` class in `src/monitoring.py` logs F1 and AUC over time and fires an alert when performance degrades >15% from baseline â€” a lightweight simulation of production model health monitoring.

---

## ğŸƒ End-to-End Flow

```
model.py â†’ cleaned_churn_data.csv + best_model.pkl + shap_explainer.pkl
    â†“
src/app.py   â†’  REST API  (POST /predict + SHAP top drivers)
dashboard.py â†’  Web UI    (EDA + live prediction + SHAP chart)
analysis.sql â†’  SQL insights for marketing/CRM
src/run_monitoring.py â†’ Drift checks & performance logging
```

---

*Aditya Mahale â€” [GitHub](https://github.com/AdityaM24) | Dataset: IBM Telco Customer Churn*
